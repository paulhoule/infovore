<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans" 
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xmlns:context="http://www.springframework.org/schema/context"
     xmlns:c="http://www.springframework.org/schema/c"
     xmlns:p="http://www.springframework.org/schema/p"
    xsi:schemaLocation="http://www.springframework.org/schema/beans
         http://www.springframework.org/schema/beans/spring-beans.xsd
         http://www.springframework.org/schema/context
         http://www.springframework.org/schema/context/spring-context.xsd">

  <!-- comment numbering works like ISO 9001 or a PMI book just not so deep a hierarchy the top level schema is now 1 configuration of Spring itself 2 configuration of general infovore beans 3 bean definitions for Amazon EMR -->

  <!-- 1.0 automatically scan classpath for apps -->

  <context:component-scan base-package="com.ontology2.haruhi">
    <context:include-filter type="assignable" expression="com.ontology2.centipede.shell.CommandLineApplication" />
    <context:exclude-filter type="assignable" expression="com.ontology2.haruhi.HaruhiShell" />
  </context:component-scan>

  <!-- 1.1 make system properties available -->
  <bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer" />


  <!-- 2.0 configuration of major resources -->
  <bean name="s3JarPath" class="java.lang.String">
    <constructor-arg value="s3://bakemono-public/" />
  </bean>

  <bean name="localCmdCluster defaultCluster" class="com.ontology2.haruhi.LocalCmdCluster">
    <property name="mavenRepoPath">
      <value>${user.home}/.m2/repository</value>
    </property>
  </bean>

  <!-- the defaultJar is the default JAR we run; override it to change the default -->
  <!-- bakemonoJar sets the defaults for bakemono derivatives; inherit from it -->

  <bean name="bakemonoJar defaultJar" class="com.ontology2.haruhi.MavenManagedJar">
    <property name="groupId" value="com.ontology2" />
    <property name="artifactId" value="bakemono" />
    <property name="version" value="2.0-SNAPSHOT" />
    <property name="classifier" value="job" />
    <property name="headArguments">
      <list>
        <value>run</value>
      </list>
    </property>
  </bean>
  
  <!-- 2.1.1 definitions of flows -->
  <!-- arg0: s3n://freebase-dumps/ -->
  <!-- arg1: 2013-10-06-00 -->
  <!-- arg2: s3n://basekb-lime/ -->
  
  <bean name="basekbNowFlow" class="com.ontology2.haruhi.flows.SpringFlow">
    <constructor-arg>
      <list>
      <bean class="com.ontology2.haruhi.flows.AssignmentStep">
            <constructor-arg>
              <list>
                <bean class="com.ontology2.haruhi.flows.Assignment" c:assignTo="input" c:expression="#$0+'freebase-rdf-'+#$1+'/'" />
                <bean class="com.ontology2.haruhi.flows.Assignment" c:assignTo="preprocessed" c:expression="tmpDir+'preprocessed/'+#$1+'/'" />
                <bean class="com.ontology2.haruhi.flows.Assignment" c:assignTo="outputRoot" c:expression="#$2+#$1+'/'" />
              </list>
            </constructor-arg>
       </bean>
       <bean class="com.ontology2.haruhi.flows.AssignmentStep">
            <constructor-arg>
              <list>
                <bean class="com.ontology2.haruhi.flows.Assignment" c:assignTo="accepted" c:expression="#outputRoot+'accepted/'" />
                <bean class="com.ontology2.haruhi.flows.Assignment" c:assignTo="sieved" c:expression="#outputRoot+'sieved/'" />
              </list>
            </constructor-arg>
       </bean>
       <bean class="com.ontology2.haruhi.flows.JobStep">
            <constructor-arg>
              <list>
                <value>'run'</value>
                <value>'freebaseRDFPrefilter'</value>
                <value>#input</value>
                <value>#preprocessed</value>
              </list>
            </constructor-arg>
        </bean>  
        <bean class="com.ontology2.haruhi.flows.JobStep">
            <constructor-arg>
              <list>
                <value>'run'</value>
                <value>'pse3'</value>
                <value>#preprocessed</value>
                <value>#outputRoot</value>
              </list>
            </constructor-arg>
        </bean>
        <bean class="com.ontology2.haruhi.flows.JobStep">
            <constructor-arg>
              <list>
                <value>'run'</value>
                <value>'sieve3'</value>
                <value>#accepted</value>
                <value>#sieved</value>
              </list>
            </constructor-arg>
        </bean>
        <bean class="com.ontology2.haruhi.flows.JobStep">
            <constructor-arg>
              <list>
                <value>'run'</value>
                <value>'fs'</value>
                <value>'-rmr'</value>
                <value>#accepted</value>
                <value>#preprocessed</value>
              </list>
            </constructor-arg>
        </bean>
      </list>
    </constructor-arg>
  </bean>

  <bean name="t20130902" parent="bakemonoJar">
    <property name="version" value="t20130902" />
  </bean>
  
  <!-- 3.0 Bean Definitions For Amazon EMR that the user almost certainly needs to change -->
  <!-- note that this all depends on a "awsCredentials" object being defined in your .haruhi/applicaionContext.xml -->
  <!-- we're not going to reference this from inside Spring because we don't want to force you to set -->
  <!-- AWS credentials if you are not using AWS -->

  <bean name="awsCredentials" class="com.amazonaws.auth.AWSCredentials">
    <constructor-arg value="redacted" />
    <constructor-arg value="redacted" />
  </bean>

  <bean name="awsLogUri" class="java.lang.String">
    <constructor-arg value="s3://bakemono-logs/" />
  </bean>

  <bean name="awsSoftwareBucket" class="java.lang.String">
    <constructor-arg value="s3://bakemono-public/" />
  </bean>
  
  <!-- 3.1 definition of commonly used objects-->
  
  <bean name="emrClient" class="com.amazonaws.services.elasticmapreduce.AmazonElasticMapReduceClient">
    <constructor-arg ref="awsCredentials"/>
  </bean>
  
  <bean name="stepFactory" class="com.amazonaws.services.elasticmapreduce.util.StepFactory" />
  
  <bean name="debugStep" scope="prototype" class="com.amazonaws.services.elasticmapreduce.model.StepConfig">
    <property name="name" value="Enable Debugging" />
    <property name="actionOnFailure" value="TERMINATE_JOB_FLOW" />
    <property name="hadoopJarStep">
      <bean factory-bean="stepFactory" factory-method="newEnableDebuggingStep" />
    </property>
  </bean>

  <bean name="rootInstancesDefinition" class="com.amazonaws.services.elasticmapreduce.model.JobFlowInstancesConfig" abstract="true">
    <property name="hadoopVersion" value="1.0.3" />
    <property name="masterInstanceType" value="m1.small" />
    <property name="slaveInstanceType" value="c1.medium" />
    <property name="keepJobFlowAliveWhenNoSteps" value="false" />
    <property name="instanceCount" value="2" /> <!--  the master + 1 slave = 1 -->
  </bean>
  
  <!--  3.2 here we define specific clusters that you might want to use -->
  
  <!--  cheapest feasible cluster,  contains just the master node which does double -->
  <!--  duties as JobTracker and TaskTracker;  this will get work done,  but slowly --> 
  <!--  great for testing lifecycle issues (will the job even start?) -->
  
  <bean name="tinyAwsCluster" class="com.ontology2.haruhi.AmazonEMRCluster">
    <constructor-arg>
       <bean parent="rootInstancesDefinition">
        <property name="instanceCount" value="1" /> 
       </bean>
    </constructor-arg>
  </bean>
  
  <!-- this cluster is suitable for small runs with real data-->
  
  <bean name="c1LargeX2AwsCluster smallAwsCluster" class="com.ontology2.haruhi.AmazonEMRCluster">
    <constructor-arg>
      <bean parent="rootInstancesDefinition">
        <property name="masterInstanceType" value="m1.medium" />
        <property name="slaveInstanceType" value="c1.xlarge" />
        <property name="instanceCount" value="3" /> <!-- 1 master + 2 slaves --> 
      </bean>
    </constructor-arg>
  </bean>
  
    <bean name="c1LargeX6AwsCluster mediumAwsCluster" class="com.ontology2.haruhi.AmazonEMRCluster">
    <constructor-arg>
      <bean parent="rootInstancesDefinition">
        <property name="masterInstanceType" value="m1.medium" />
        <property name="slaveInstanceType" value="c1.xlarge" />
        <property name="instanceCount" value="7" /> <!-- 1 master + 6 slaves --> 
      </bean>
    </constructor-arg>
    </bean>
   <bean name="c1LargeX12AwsCluster largeAwsCluster" class="com.ontology2.haruhi.AmazonEMRCluster">
    <constructor-arg>
      <bean parent="rootInstancesDefinition">
        <property name="masterInstanceType" value="m1.large" />
        <property name="slaveInstanceType" value="c1.xlarge" />
        <property name="instanceCount" value="13" /> <!-- 1 master + 12 slaves --> 
      </bean>
    </constructor-arg>
  </bean>
</beans>
 
